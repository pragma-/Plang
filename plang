#!/usr/bin/env perl

use warnings;
use strict;

# allow loading .pm modules from the current directory
BEGIN {
    unshift @INC, '.';
}

use Lexer;
use Parser;
use Grammar qw/Program/;

# our lexer
my $lexer = Lexer->new;

# discard token
sub discard {''}

# define the tokens our lexer will recognize
# (this table is quite incomplete and will be fleshed out as the language progresses)
$lexer->define_tokens(
  # [ TOKEN_TYPE,      MATCH REGEX,    OPTIONAL TOKEN BUILDER,  OPTIONAL SUB-LEXER ]
    ['COMMENT_EOL',    qr{\G(   (?://|\#).*$        )}x,  \&discard],
    ['COMMENT_INLINE', qr{\G(   /\* .*? \*/         )}x,  \&discard],
    ['COMMENT_MULTI',  qr{\G(   /\* .*?(?!\*/)\s+$  )}x,  \&discard, sub { multiline_comment(@_) }],
    ['DQUOTE_STRING',  qr{\G(   "(?:[^"\\]|\\.)*"   )}x],
    ['SQUOTE_STRING',  qr{\G(   '(?:[^'\\]|\\.)*'   )}x],
    ['EQ_EQ',          qr{\G(   ==                  )}x],
    ['PLUS_EQ',        qr{\G(   \+=                 )}x],
    ['PLUS_PLUS',      qr{\G(   \+\+                )}x],
    ['EQ',             qr{\G(   =                   )}x],
    ['PLUS',           qr{\G(   \+                  )}x],
    ['MINUS',          qr{\G(   -                   )}x],
    ['COMMA',          qr{\G(   ,                   )}x],
    ['STAR',           qr{\G(   \*                  )}x],
    ['BSLASH',         qr{\G(   /                   )}x],
    ['FSLASH',         qr{\G(   \\                  )}x],
    ['L_PAREN',        qr{\G(   \(                  )}x],
    ['R_PAREN',        qr{\G(   \)                  )}x],
    ['NUM',            qr{\G(   [0-9.]+             )}x],
    ['IDENT',          qr{\G(   [A-Za-z_]\w*        )}x],
    ['TERM',           qr{\G(   ;\n* | \n+          )}x],
    ['WHITESPACE',     qr{\G(   \s+                 )}x,  \&discard],
    ['OTHER',          qr{\G(   .                   )}x],
);

# sub-lexer for a multi-line comment token
sub multiline_comment {
    my ($lexer, $input, $text, $tokentype, $buf, $tokenbuilder) = @_;

    while (1) {
        $lexer->{line}++, $$text = $input->() if not defined $$text;

        if (not defined $$text) {
            return defined $tokenbuilder ? $tokenbuilder->() : [$tokentype, $buf];
        }

        if ($$text =~ m{\G( .*? \*/ \s* )}gcx) {
            $buf .= $1;
            return defined $tokenbuilder ? $tokenbuilder->() : [$tokentype, $buf];
        } else {
            $$text =~ m{\G( .* \s* )}gxc;
            $buf .= $1;
            $$text = undef;
        }
    }
}

# Grammar: DumpToken --> *
sub DumpToken {
    my ($parser) = @_;
    return $parser->next_token;
}

# iterates over lines of standard input
my $input_iter = sub { <STDIN> };

# iterates over tokens returned by lexer
my $token_iter = $lexer->tokens($input_iter);

# our parser and its token iterator
my $parser = Parser->new(token_iter => $token_iter);

# if -dumptokens was specified on command-line, use the DumpToken rule
# otherwise use the Program rule
if (grep { $_ eq '--dumptokens' } @ARGV) {
    $parser->add_rule(\&DumpToken); # generates all the tokens as a flat list
} else {
    $parser->add_rule(\&Program);   # generates an abstract syntax tree for a plang program
}

# parse the input into $result
my $result = $parser->parse;

my $err_count = @{$parser->{diagnostics}};

if ($err_count) {
    foreach my $diagnostic (@{$parser->{diagnostics}}) {
        print STDERR $diagnostic, "\n";
    }

    print STDERR "$err_count error", $err_count == 1 ? '' : 's', ".\n";
    exit 1;
}

# dump the $result data structure
use Data::Dumper;
$Data::Dumper::Terse = 1;
print Dumper $result;
